서연
1. 
1. forEach
2. <%=

2.
get 을 post

재근
1.b
2. <%= 변수 %>
3. b

준희
1.3
2.<%- include("./include/_header") %>
3. 4



1.결정트리에서 분할 기준을 선택할 때 가장 적절한 설명은?
A. 트리의 모든 노드는 동일한 특성으로 분할해야 한다.
B. 특성의 스케일을 맞춰야 정확한 분할이 가능하다.
C. 정보 이득이 높은 특성을 기준으로 하나만 선택하여 분할한다.
D. 모든 특성을 한 번씩 사용한 후 최종 분할을 한다.
E. 특성이 많을수록 항상 더 깊은 트리를 만든다.



2.랜덤포레스트와 그래디언트 부스팅의 비교로 틀린 것은?
A. 랜덤포레스트는 각 트리를 독립적으로 훈련시킨다.
B. 그래디언트 부스팅은 이전 모델의 오차를 기반으로 다음 트리를 훈련시킨다.
C. 랜덤포레스트는 예측 시 평균을, 그래디언트 부스팅은 가중합을 사용한다.
D. 랜덤포레스트는 오차에 더 민감하여 이상치에 강하다.
E. 그래디언트 부스팅은 순차적으로 모델을 조합한다.

3. 트리 알고리즘의 특징으로 올바른 설명은?
A. 트리는 특성 간 상관관계가 높을수록 성능이 좋다.
B. 트리는 연속형 특성보다 범주형 특성에서만 사용할 수 있다.
C. 트리는 스케일 조정(정규화)을 반드시 해야 한다.
D. 트리는 특성의 스케일에 영향을 받지 않는다.
E. 트리는 항상 모든 특성을 골고루 사용하여 훈련된다.


4.
A. 트리의 최대 깊이를 제한한다.
B. 학습률(learning rate)을 조절한다.
C. 트리 개수를 아주 크게 설정한다.
D. 조기 종료(early stopping)를 설정한다.
E. 검증 세트를 활용해 하이퍼파라미터를 튜닝한다.


5.다음 중 앙상블 모델이 과적합을 줄이는 방식으로 가장 적절한 설명은?
A. 동일한 데이터를 모든 모델에 반복 사용해서 학습한다.
B. 앙상블은 성능 향상보다 해석력을 높이기 위한 방법이다.
C. 다양한 모델을 조합하여 편향을 증가시키는 방식이다.
D. 모델 간의 다양성을 확보하여 과적합을 줄인다.
E. 앙상블은 단일 모델보다 항상 느리고 부정확하다.

6. 트리 모델에서 정규화를 하지 않아도 되는 이유를 설명하시오.
(힌트: 로지스틱 회귀와 비교하여)

7. 랜덤포레스트(RandomForest) 모델이 과적합을 방지하기 위해 사용하는 두 가지 주요 랜덤 요소를 설명하시오.

8. 그래디언트 부스팅(Gradient Boosting) 알고리즘의 학습 과정은 기존 모델이 만든 **오류(잔차)**를 줄여가는 방식이다. 이 점을 바탕으로, 그래디언트 부스팅이 오류(노이즈)에 민감한 이유를 설명하시오.



1.c : 결정트리는 각 노드마다 하나의 특성을 선택해 분할. 가장 정보 이득이 큰 특성을 선택함.
2.d : 	그래디언트 부스팅이 오차에 민감함. 랜덤포레스트는 오차에 덜 민감 (평균 내기 때문).
3.d : 트리는 스케일에 민감하지 않아 정규화가 필요 없음. 수치의 절대값보다는 조건(기준값)에 따라 분기함.
4.c : 	트리 개수를 무작정 크게 하면 오히려 과적합 위험이 커짐. 적절한 조절 필요.
5.d : 	앙상블은 서로 다른 관점을 가진 여러 모델을 조합해 과적합을 줄이고 일반화 성능을 높임.
6. 로지스틱 회귀는 상대적인 스케일에 따라 가중치가 달라지지만, 트리모델은 분할값 이라는 기준으로 브랜치가 생성되어서 상대적인 비교(정규화)를 하지 않아도 됨,
7. 데이터 선택의 랜덤성, 특성 선택의 랜덤성(전체 중 일부 특성만 선택)
8. GB는 오류에 집중하여 트리를(오류 개선모델) 생성하고 모델을 업데이트(앙상블) 하는 방식, 오류에 민감함